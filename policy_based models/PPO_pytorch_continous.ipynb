{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P4ocnfC77Beq",
    "outputId": "096db2fa-e0c8-4b5a-a2be-356c47142ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting box2d-py\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/34/da5393985c3ff9a76351df6127c275dcb5749ae0abbe8d5210f06d97405d/box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 5.2MB/s \n",
      "\u001b[?25hInstalling collected packages: box2d-py\n",
      "Successfully installed box2d-py-2.3.8\n",
      "Collecting gym[Box_2D]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/f2/e7ee20bf02b2d02263becba1c5ec4203fef7cfbd57759e040e51307173f4/gym-0.18.0.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 6.0MB/s \n",
      "\u001b[33m  WARNING: gym 0.18.0 does not provide the extra 'box_2d'\u001b[0m\n",
      "\u001b[?25hCollecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/91/ee427c42957f8c4cbe477bf4f8b7f608e003a17941e509d1777e58648cb3/scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4MB 108kB/s \n",
      "\u001b[?25hCollecting numpy>=1.10.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ef/8967d406f3f85018ceb5efab50431e901683188f1741ceb053efcab26c87/numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3MB 118kB/s \n",
      "\u001b[?25hCollecting pyglet<=1.5.0,>=1.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 38.4MB/s \n",
      "\u001b[?25hCollecting Pillow<=7.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/f2/6722dd0c22e3a143ac792ccb2424924ac72af4adea756b1165b4cad50da7/Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 40.5MB/s \n",
      "\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
      "Collecting future\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 43.5MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gym: filename=gym-0.18.0-cp37-none-any.whl size=1656450 sha256=809e33ef97773e7ab9b9d356258e4384aaba05552831564be159b700f03ca010\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/85/3b/480b828a4a697b37392740a040b8989f729d952b4e441a1877\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=3601deb14d8a9aee345f685ff7b9a00e274aa6c79603e31ba560238d3b83925a\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "Successfully built gym future\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, future, pyglet, Pillow, cloudpickle, gym\n",
      "  Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "  Found existing installation: pyglet 1.5.0\n",
      "    Uninstalling pyglet-1.5.0:\n",
      "      Successfully uninstalled pyglet-1.5.0\n",
      "  Found existing installation: Pillow 7.1.2\n",
      "    Uninstalling Pillow-7.1.2:\n",
      "      Successfully uninstalled Pillow-7.1.2\n",
      "  Found existing installation: cloudpickle 1.3.0\n",
      "    Uninstalling cloudpickle-1.3.0:\n",
      "      Successfully uninstalled cloudpickle-1.3.0\n",
      "  Found existing installation: gym 0.17.3\n",
      "    Uninstalling gym-0.17.3:\n",
      "      Successfully uninstalled gym-0.17.3\n",
      "Successfully installed Pillow-7.2.0 cloudpickle-1.6.0 future-0.18.2 gym-0.18.0 numpy-1.20.2 pyglet-1.5.0 scipy-1.6.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL",
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall box2d-py\n",
    "!pip install --upgrade --force-reinstall gym[Box_2D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IHFmodk7Hv4"
   },
   "outputs": [],
   "source": [
    "# This improved implementation is based on\n",
    "# https://github.com/MohammedElm/Reinforcement-Learning---Lunar-Lander/blob/main/PPO%20implementation%20from%20scratch.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions.normal as tdn\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_p815V-lC5A7"
   },
   "outputs": [],
   "source": [
    "class actor(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(actor, self).__init__()\n",
    "        self.inputs = nn.Linear(input_shape, 512)\n",
    "        self.input_activation = nn.ReLU()\n",
    "        self.input_mean = nn.Linear(512, 512)\n",
    "        self.output_mean = nn.Linear(512, output_shape)\n",
    "        self.actor_mean = nn.Tanh()\n",
    "        self.input_sigma = nn.Linear(512, 512)\n",
    "        self.output_sigma = nn.Linear(512, output_shape)\n",
    "        self.actor_sigma = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lvl1 = self.inputs(x)\n",
    "        lvl1 = self.input_activation(lvl1)\n",
    "\n",
    "        means = self.input_mean(lvl1)\n",
    "        means = self.input_activation(means)\n",
    "        means = self.output_mean(means)\n",
    "        means = self.actor_mean(means)\n",
    "\n",
    "        sigmas = self.input_sigma(lvl1)\n",
    "        sigmas = self.input_activation(sigmas)\n",
    "        sigmas = self.output_sigma(sigmas)\n",
    "        sigmas = self.actor_sigma(sigmas)\n",
    "        return means, sigmas\n",
    "\n",
    "\n",
    "class critic(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(critic, self).__init__()\n",
    "\n",
    "        self.inputs = nn.Linear(input_shape, 512)\n",
    "        self.input_activation = nn.ReLU()\n",
    "        self.layers = nn.Linear(512, 512)\n",
    "        self.output = nn.Linear(512, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lvl = self.inputs(x)\n",
    "        lvl = self.input_activation(lvl)\n",
    "        lvl = self.layers(lvl)\n",
    "        lvl = self.input_activation(lvl)\n",
    "        outputs = self.output(lvl)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZUIlb7iF5br"
   },
   "outputs": [],
   "source": [
    "problem = \"LunarLanderContinuous-v2\"\n",
    "RANDOM_SEEDS = 123\n",
    "\n",
    "gym_env = gym.make(problem)\n",
    "gym_env.seed(RANDOM_SEEDS)\n",
    "torch.manual_seed(RANDOM_SEEDS)\n",
    "\n",
    "gym_env.reset()\n",
    "\n",
    "max_episodes = 2000\n",
    "lambda_advantage = 0.99\n",
    "state_shape = gym_env.observation_space.shape[0]\n",
    "action_dim = gym_env.action_space.shape[0]\n",
    "upper_bound = gym_env.action_space.high[0]\n",
    "lower_bound = gym_env.action_space.low[0]\n",
    "epsilon=0.2\n",
    "n_updates=10 \n",
    "lr_critic=1e-3\n",
    "lr_actor=1e-5\n",
    "max_step = 500\n",
    "\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUka9KiuGvys"
   },
   "outputs": [],
   "source": [
    "ep_reward_list = []\n",
    "ep_steps_list = []\n",
    "avg_reward_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqSRHYP3Hhlq"
   },
   "outputs": [],
   "source": [
    "actor_model = actor(state_shape, action_dim)\n",
    "critic_model = critic(state_shape, 1)\n",
    "optimizer_actor = optim.Adam(actor_model.parameters(), lr=lr_actor)\n",
    "optimizer_critic = optim.Adam(critic_model.parameters(), lr=lr_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_pdf(x,mu,sigma):\n",
    "    dist = tdn.Normal(loc=mu, scale=torch.sqrt(sigma))\n",
    "    return dist.log_prob(x).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iNyxZDMkIN8T",
    "outputId": "ece1fbb1-4e1f-4636-ce51-59a0bf8802bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Steps 122  * Episodic Reward is ==> -311.74136122312734 * Lastest 100 Episods Avg Reward is ==> -311.74136122312734\n",
      "Episode * 10 * Steps 117  * Episodic Reward is ==> -286.7217417480599 * Lastest 100 Episods Avg Reward is ==> -255.908233379371\n",
      "Episode * 20 * Steps 72  * Episodic Reward is ==> -89.60655379798544 * Lastest 100 Episods Avg Reward is ==> -222.41724854916876\n",
      "Episode * 30 * Steps 90  * Episodic Reward is ==> -99.09222336681484 * Lastest 100 Episods Avg Reward is ==> -177.06596070009445\n",
      "Episode * 40 * Steps 103  * Episodic Reward is ==> -104.1200843970753 * Lastest 100 Episods Avg Reward is ==> -176.80681748672438\n",
      "Episode * 50 * Steps 73  * Episodic Reward is ==> -133.67448781866773 * Lastest 100 Episods Avg Reward is ==> -171.39685901345197\n",
      "Episode * 60 * Steps 113  * Episodic Reward is ==> -243.66126981538073 * Lastest 100 Episods Avg Reward is ==> -164.48640983184845\n",
      "Episode * 70 * Steps 99  * Episodic Reward is ==> -134.05915465365052 * Lastest 100 Episods Avg Reward is ==> -155.71258616793153\n",
      "Episode * 80 * Steps 73  * Episodic Reward is ==> -55.09720869878881 * Lastest 100 Episods Avg Reward is ==> -152.77319344643018\n",
      "Episode * 90 * Steps 80  * Episodic Reward is ==> -51.92355362282921 * Lastest 100 Episods Avg Reward is ==> -149.17280267427444\n",
      "Episode * 100 * Steps 105  * Episodic Reward is ==> -114.68147841839041 * Lastest 100 Episods Avg Reward is ==> -146.12149304298262\n",
      "Episode * 110 * Steps 150  * Episodic Reward is ==> -316.1416375906827 * Lastest 100 Episods Avg Reward is ==> -134.11036171535017\n",
      "Episode * 120 * Steps 68  * Episodic Reward is ==> -60.99899986660479 * Lastest 100 Episods Avg Reward is ==> -127.6630027463657\n",
      "Episode * 130 * Steps 108  * Episodic Reward is ==> -124.39288266444726 * Lastest 100 Episods Avg Reward is ==> -129.98012043025392\n",
      "Episode * 140 * Steps 180  * Episodic Reward is ==> -129.2163310889881 * Lastest 100 Episods Avg Reward is ==> -127.7408000103028\n",
      "Episode * 150 * Steps 132  * Episodic Reward is ==> -80.44228295734332 * Lastest 100 Episods Avg Reward is ==> -121.61185584641197\n",
      "Episode * 160 * Steps 113  * Episodic Reward is ==> -91.4664078031932 * Lastest 100 Episods Avg Reward is ==> -117.7781662837628\n",
      "Episode * 170 * Steps 131  * Episodic Reward is ==> -42.27419237607209 * Lastest 100 Episods Avg Reward is ==> -116.58163502246654\n",
      "Episode * 180 * Steps 197  * Episodic Reward is ==> -65.95519103079208 * Lastest 100 Episods Avg Reward is ==> -113.29615749370718\n",
      "Episode * 190 * Steps 152  * Episodic Reward is ==> -150.31904611212445 * Lastest 100 Episods Avg Reward is ==> -109.1795662304622\n",
      "Episode * 200 * Steps 237  * Episodic Reward is ==> -204.5738705471132 * Lastest 100 Episods Avg Reward is ==> -102.74447917572908\n",
      "Episode * 210 * Steps 140  * Episodic Reward is ==> 11.32866548203151 * Lastest 100 Episods Avg Reward is ==> -95.17513417965542\n",
      "Episode * 220 * Steps 99  * Episodic Reward is ==> -159.6136833749498 * Lastest 100 Episods Avg Reward is ==> -90.8361348958053\n",
      "Episode * 230 * Steps 500  * Episodic Reward is ==> 61.96281795914791 * Lastest 100 Episods Avg Reward is ==> -89.17098360287406\n",
      "Episode * 240 * Steps 141  * Episodic Reward is ==> -346.2337057775028 * Lastest 100 Episods Avg Reward is ==> -84.03306045598397\n",
      "Episode * 250 * Steps 183  * Episodic Reward is ==> 13.40894602953891 * Lastest 100 Episods Avg Reward is ==> -76.77648588834761\n",
      "Episode * 260 * Steps 184  * Episodic Reward is ==> -53.84656923069897 * Lastest 100 Episods Avg Reward is ==> -73.8662819356823\n",
      "Episode * 270 * Steps 215  * Episodic Reward is ==> -64.64385744338857 * Lastest 100 Episods Avg Reward is ==> -68.44290627664382\n",
      "Episode * 280 * Steps 133  * Episodic Reward is ==> -3.5296334129238858 * Lastest 100 Episods Avg Reward is ==> -61.839218976223805\n",
      "Episode * 290 * Steps 500  * Episodic Reward is ==> 75.7378380375959 * Lastest 100 Episods Avg Reward is ==> -56.47615537833939\n",
      "Episode * 300 * Steps 500  * Episodic Reward is ==> 42.518153912419905 * Lastest 100 Episods Avg Reward is ==> -52.23107411383355\n",
      "Episode * 310 * Steps 106  * Episodic Reward is ==> -1.2758981859168301 * Lastest 100 Episods Avg Reward is ==> -47.41114949148301\n",
      "Episode * 320 * Steps 361  * Episodic Reward is ==> -202.9795143146946 * Lastest 100 Episods Avg Reward is ==> -52.04424967462547\n",
      "Episode * 330 * Steps 210  * Episodic Reward is ==> 16.07843806578076 * Lastest 100 Episods Avg Reward is ==> -48.21026715309739\n",
      "Episode * 340 * Steps 169  * Episodic Reward is ==> -172.11953587024544 * Lastest 100 Episods Avg Reward is ==> -47.92035350137222\n",
      "Episode * 350 * Steps 500  * Episodic Reward is ==> 57.319915740571886 * Lastest 100 Episods Avg Reward is ==> -54.342551856911214\n",
      "Episode * 360 * Steps 500  * Episodic Reward is ==> -1.216119875002783 * Lastest 100 Episods Avg Reward is ==> -57.1364714161743\n",
      "Episode * 370 * Steps 500  * Episodic Reward is ==> 24.85398116869549 * Lastest 100 Episods Avg Reward is ==> -53.28927362655681\n",
      "Episode * 380 * Steps 374  * Episodic Reward is ==> -173.34301437381475 * Lastest 100 Episods Avg Reward is ==> -50.13274451287175\n",
      "Episode * 390 * Steps 500  * Episodic Reward is ==> 89.30938201317677 * Lastest 100 Episods Avg Reward is ==> -57.269095320624814\n",
      "Episode * 400 * Steps 500  * Episodic Reward is ==> -20.975841648349714 * Lastest 100 Episods Avg Reward is ==> -52.41780305021292\n",
      "Episode * 410 * Steps 393  * Episodic Reward is ==> -453.52014917361913 * Lastest 100 Episods Avg Reward is ==> -60.81476015035841\n",
      "Episode * 420 * Steps 239  * Episodic Reward is ==> -189.60834232878898 * Lastest 100 Episods Avg Reward is ==> -49.3932082827006\n",
      "Episode * 430 * Steps 500  * Episodic Reward is ==> 111.63532429853059 * Lastest 100 Episods Avg Reward is ==> -36.76944706331709\n",
      "Episode * 440 * Steps 500  * Episodic Reward is ==> 108.78336053411827 * Lastest 100 Episods Avg Reward is ==> -22.413036003072566\n",
      "Episode * 450 * Steps 224  * Episodic Reward is ==> -5.6656828620213275 * Lastest 100 Episods Avg Reward is ==> -11.727153077701272\n",
      "Episode * 460 * Steps 237  * Episodic Reward is ==> 12.78832516256223 * Lastest 100 Episods Avg Reward is ==> 2.2497750766972047\n",
      "Episode * 470 * Steps 500  * Episodic Reward is ==> 62.201151323991375 * Lastest 100 Episods Avg Reward is ==> 6.433187532811406\n",
      "Episode * 480 * Steps 500  * Episodic Reward is ==> 100.80501175246982 * Lastest 100 Episods Avg Reward is ==> 5.654619533902786\n",
      "Episode * 490 * Steps 195  * Episodic Reward is ==> -52.79901801874155 * Lastest 100 Episods Avg Reward is ==> 22.458523907763823\n",
      "Episode * 500 * Steps 500  * Episodic Reward is ==> 179.08278536366618 * Lastest 100 Episods Avg Reward is ==> 22.912987784670044\n",
      "Episode * 510 * Steps 500  * Episodic Reward is ==> 144.11844283809873 * Lastest 100 Episods Avg Reward is ==> 33.8877688191488\n",
      "Episode * 520 * Steps 500  * Episodic Reward is ==> 143.99788849922555 * Lastest 100 Episods Avg Reward is ==> 44.18567580208154\n",
      "Episode * 530 * Steps 182  * Episodic Reward is ==> 50.89074624643993 * Lastest 100 Episods Avg Reward is ==> 45.034794709614715\n",
      "Episode * 540 * Steps 500  * Episodic Reward is ==> 112.05855427627162 * Lastest 100 Episods Avg Reward is ==> 40.693195776271075\n",
      "Episode * 550 * Steps 169  * Episodic Reward is ==> 25.20944317832769 * Lastest 100 Episods Avg Reward is ==> 33.40926116969594\n",
      "Episode * 560 * Steps 500  * Episodic Reward is ==> 115.92505528751164 * Lastest 100 Episods Avg Reward is ==> 30.732060485757998\n",
      "Episode * 570 * Steps 327  * Episodic Reward is ==> -319.7609451142682 * Lastest 100 Episods Avg Reward is ==> 23.26069481799359\n",
      "Episode * 580 * Steps 500  * Episodic Reward is ==> 148.75082986625628 * Lastest 100 Episods Avg Reward is ==> 30.174451555873038\n",
      "Episode * 590 * Steps 500  * Episodic Reward is ==> 46.8433598829458 * Lastest 100 Episods Avg Reward is ==> 18.916521283386167\n",
      "Episode * 600 * Steps 500  * Episodic Reward is ==> 155.92940290966405 * Lastest 100 Episods Avg Reward is ==> 14.095186265859923\n",
      "Episode * 610 * Steps 500  * Episodic Reward is ==> 80.69638778327396 * Lastest 100 Episods Avg Reward is ==> 18.00786354813207\n",
      "Episode * 620 * Steps 173  * Episodic Reward is ==> 45.79361383338741 * Lastest 100 Episods Avg Reward is ==> 9.944984463803854\n",
      "Episode * 630 * Steps 180  * Episodic Reward is ==> 16.364269235451175 * Lastest 100 Episods Avg Reward is ==> 6.850555452630479\n",
      "Episode * 640 * Steps 164  * Episodic Reward is ==> 41.94650958915264 * Lastest 100 Episods Avg Reward is ==> 11.230825776180303\n",
      "Episode * 650 * Steps 500  * Episodic Reward is ==> 147.26665885466704 * Lastest 100 Episods Avg Reward is ==> 21.56212936659138\n",
      "Episode * 660 * Steps 249  * Episodic Reward is ==> -227.03312647866227 * Lastest 100 Episods Avg Reward is ==> 27.740774395682493\n",
      "Episode * 670 * Steps 500  * Episodic Reward is ==> 165.53336993074987 * Lastest 100 Episods Avg Reward is ==> 43.3557052406168\n",
      "Episode * 680 * Steps 379  * Episodic Reward is ==> -62.49004079083816 * Lastest 100 Episods Avg Reward is ==> 42.63056690856226\n",
      "Episode * 690 * Steps 494  * Episodic Reward is ==> -170.39762147846085 * Lastest 100 Episods Avg Reward is ==> 53.27254745023656\n",
      "Episode * 700 * Steps 147  * Episodic Reward is ==> 23.115880270113223 * Lastest 100 Episods Avg Reward is ==> 62.606877491998006\n",
      "Episode * 710 * Steps 252  * Episodic Reward is ==> -190.99137079283275 * Lastest 100 Episods Avg Reward is ==> 56.25618828199421\n",
      "Episode * 720 * Steps 156  * Episodic Reward is ==> 0.029047198043613776 * Lastest 100 Episods Avg Reward is ==> 56.67147456865942\n",
      "Episode * 730 * Steps 500  * Episodic Reward is ==> 180.33615483171153 * Lastest 100 Episods Avg Reward is ==> 52.06880068031932\n",
      "Episode * 740 * Steps 143  * Episodic Reward is ==> 39.64030013027153 * Lastest 100 Episods Avg Reward is ==> 55.52921767090459\n",
      "Episode * 750 * Steps 185  * Episodic Reward is ==> 41.60612869224772 * Lastest 100 Episods Avg Reward is ==> 62.88473320345552\n",
      "Episode * 760 * Steps 500  * Episodic Reward is ==> 153.71595570621372 * Lastest 100 Episods Avg Reward is ==> 68.1668409378633\n",
      "Episode * 770 * Steps 500  * Episodic Reward is ==> 131.88452090788516 * Lastest 100 Episods Avg Reward is ==> 62.797605251622464\n",
      "Episode * 780 * Steps 500  * Episodic Reward is ==> 131.612852086654 * Lastest 100 Episods Avg Reward is ==> 69.9055817242186\n",
      "Episode * 790 * Steps 500  * Episodic Reward is ==> 110.23565207141532 * Lastest 100 Episods Avg Reward is ==> 77.72804818982314\n",
      "Episode * 800 * Steps 331  * Episodic Reward is ==> -128.93800963877362 * Lastest 100 Episods Avg Reward is ==> 78.65496069608653\n",
      "Episode * 810 * Steps 500  * Episodic Reward is ==> 112.1259869797438 * Lastest 100 Episods Avg Reward is ==> 86.06856577841208\n",
      "Episode * 820 * Steps 500  * Episodic Reward is ==> 100.45836241290789 * Lastest 100 Episods Avg Reward is ==> 90.85105947715336\n",
      "Episode * 830 * Steps 198  * Episodic Reward is ==> 37.25823283566939 * Lastest 100 Episods Avg Reward is ==> 104.14522939765739\n",
      "Episode * 840 * Steps 500  * Episodic Reward is ==> 170.80495267026646 * Lastest 100 Episods Avg Reward is ==> 109.05452058973385\n",
      "Episode * 850 * Steps 500  * Episodic Reward is ==> 171.37201161807906 * Lastest 100 Episods Avg Reward is ==> 108.54854310765404\n",
      "Episode * 860 * Steps 500  * Episodic Reward is ==> 176.4210019305797 * Lastest 100 Episods Avg Reward is ==> 110.34586909804212\n",
      "Episode * 870 * Steps 500  * Episodic Reward is ==> 145.0816051510653 * Lastest 100 Episods Avg Reward is ==> 118.60795596898271\n",
      "Episode * 880 * Steps 500  * Episodic Reward is ==> 182.08475055675152 * Lastest 100 Episods Avg Reward is ==> 119.69070768081112\n",
      "Episode * 890 * Steps 352  * Episodic Reward is ==> 220.33748428664876 * Lastest 100 Episods Avg Reward is ==> 118.97961387304672\n",
      "Episode * 900 * Steps 500  * Episodic Reward is ==> 107.41167426820249 * Lastest 100 Episods Avg Reward is ==> 124.55656758705489\n",
      "Episode * 910 * Steps 500  * Episodic Reward is ==> 182.504209685404 * Lastest 100 Episods Avg Reward is ==> 135.71687915742186\n",
      "Episode * 920 * Steps 119  * Episodic Reward is ==> 28.824859920815868 * Lastest 100 Episods Avg Reward is ==> 142.59496484234515\n",
      "Episode * 930 * Steps 500  * Episodic Reward is ==> 150.5199171748582 * Lastest 100 Episods Avg Reward is ==> 136.80568127131266\n",
      "Episode * 940 * Steps 159  * Episodic Reward is ==> 6.650810763761797 * Lastest 100 Episods Avg Reward is ==> 133.7327897749054\n",
      "Episode * 950 * Steps 500  * Episodic Reward is ==> 193.27823462045595 * Lastest 100 Episods Avg Reward is ==> 136.32748775738483\n",
      "Episode * 960 * Steps 500  * Episodic Reward is ==> 155.8416595453516 * Lastest 100 Episods Avg Reward is ==> 134.10224579186394\n",
      "Episode * 970 * Steps 500  * Episodic Reward is ==> 207.22583956523098 * Lastest 100 Episods Avg Reward is ==> 129.09574009377954\n",
      "Episode * 980 * Steps 500  * Episodic Reward is ==> 161.51675256521804 * Lastest 100 Episods Avg Reward is ==> 129.87303374047866\n",
      "Episode * 990 * Steps 500  * Episodic Reward is ==> 167.4937331806632 * Lastest 100 Episods Avg Reward is ==> 132.5445556769694\n",
      "Episode * 1000 * Steps 500  * Episodic Reward is ==> 187.88810478405352 * Lastest 100 Episods Avg Reward is ==> 132.18119646197806\n",
      "Episode * 1010 * Steps 137  * Episodic Reward is ==> 36.30781324306872 * Lastest 100 Episods Avg Reward is ==> 126.93505374281968\n",
      "Episode * 1020 * Steps 500  * Episodic Reward is ==> 173.92227282517752 * Lastest 100 Episods Avg Reward is ==> 125.63864426148687\n",
      "Episode * 1030 * Steps 500  * Episodic Reward is ==> 131.8612686345615 * Lastest 100 Episods Avg Reward is ==> 131.04090555215183\n",
      "Episode * 1040 * Steps 500  * Episodic Reward is ==> 153.58722795861374 * Lastest 100 Episods Avg Reward is ==> 137.53355307462706\n",
      "Episode * 1050 * Steps 253  * Episodic Reward is ==> 273.841836041051 * Lastest 100 Episods Avg Reward is ==> 145.06011750321576\n",
      "Episode * 1060 * Steps 500  * Episodic Reward is ==> 62.569928940409426 * Lastest 100 Episods Avg Reward is ==> 147.20455565101474\n",
      "Episode * 1070 * Steps 243  * Episodic Reward is ==> 260.5029841661172 * Lastest 100 Episods Avg Reward is ==> 145.01744177590464\n",
      "Episode * 1080 * Steps 378  * Episodic Reward is ==> 258.5685134682982 * Lastest 100 Episods Avg Reward is ==> 151.13419852428353\n",
      "Episode * 1090 * Steps 205  * Episodic Reward is ==> 292.2654169576175 * Lastest 100 Episods Avg Reward is ==> 160.56859589336253\n",
      "Episode * 1100 * Steps 468  * Episodic Reward is ==> 286.9037485193684 * Lastest 100 Episods Avg Reward is ==> 166.88468082141597\n",
      "Episode * 1110 * Steps 235  * Episodic Reward is ==> 301.1820705079932 * Lastest 100 Episods Avg Reward is ==> 175.73404210515093\n",
      "Episode * 1120 * Steps 279  * Episodic Reward is ==> 274.97678907932874 * Lastest 100 Episods Avg Reward is ==> 189.92473436057273\n",
      "Episode * 1130 * Steps 500  * Episodic Reward is ==> 119.37684489400363 * Lastest 100 Episods Avg Reward is ==> 199.56999004287664\n",
      "Episode * 1140 * Steps 222  * Episodic Reward is ==> 294.83858859793236 * Lastest 100 Episods Avg Reward is ==> 208.02004289090164\n",
      "Episode * 1150 * Steps 212  * Episodic Reward is ==> 293.35703643668296 * Lastest 100 Episods Avg Reward is ==> 208.1773504669999\n",
      "Episode * 1160 * Steps 140  * Episodic Reward is ==> 35.658660156857195 * Lastest 100 Episods Avg Reward is ==> 206.98355127331126\n",
      "Episode * 1170 * Steps 359  * Episodic Reward is ==> -190.055833095514 * Lastest 100 Episods Avg Reward is ==> 211.8705407914591\n",
      "Episode * 1180 * Steps 319  * Episodic Reward is ==> 313.04861089113047 * Lastest 100 Episods Avg Reward is ==> 203.68118958446254\n",
      "Episode * 1190 * Steps 140  * Episodic Reward is ==> 13.5102247150584 * Lastest 100 Episods Avg Reward is ==> 190.56733049014682\n",
      "Episode * 1200 * Steps 500  * Episodic Reward is ==> 137.63839196511856 * Lastest 100 Episods Avg Reward is ==> 187.42390711466794\n",
      "Episode * 1210 * Steps 108  * Episodic Reward is ==> 30.45359430217181 * Lastest 100 Episods Avg Reward is ==> 179.7038401827037\n",
      "Episode * 1220 * Steps 94  * Episodic Reward is ==> 7.584526168046182 * Lastest 100 Episods Avg Reward is ==> 164.6089697827018\n",
      "Episode * 1230 * Steps 279  * Episodic Reward is ==> -187.9336037570021 * Lastest 100 Episods Avg Reward is ==> 147.30434122925806\n",
      "Episode * 1240 * Steps 114  * Episodic Reward is ==> 19.078206895343016 * Lastest 100 Episods Avg Reward is ==> 129.91373934300134\n",
      "Episode * 1250 * Steps 109  * Episodic Reward is ==> 37.64137937378163 * Lastest 100 Episods Avg Reward is ==> 119.9136739483315\n",
      "Episode * 1260 * Steps 104  * Episodic Reward is ==> 7.069243416063657 * Lastest 100 Episods Avg Reward is ==> 116.34133682485299\n",
      "Episode * 1270 * Steps 158  * Episodic Reward is ==> -0.9164445859412211 * Lastest 100 Episods Avg Reward is ==> 119.41089371664678\n",
      "Episode * 1280 * Steps 500  * Episodic Reward is ==> 107.70419219052569 * Lastest 100 Episods Avg Reward is ==> 111.92453436842602\n",
      "Episode * 1290 * Steps 227  * Episodic Reward is ==> -99.4482929130914 * Lastest 100 Episods Avg Reward is ==> 105.38888150858304\n",
      "Episode * 1300 * Steps 95  * Episodic Reward is ==> 37.63386590627408 * Lastest 100 Episods Avg Reward is ==> 100.63937782978896\n",
      "Episode * 1310 * Steps 142  * Episodic Reward is ==> 43.96826912943436 * Lastest 100 Episods Avg Reward is ==> 101.07745317480959\n",
      "Episode * 1320 * Steps 117  * Episodic Reward is ==> 57.923209790679834 * Lastest 100 Episods Avg Reward is ==> 108.2894736663819\n",
      "Episode * 1330 * Steps 500  * Episodic Reward is ==> 1.4287301118510811 * Lastest 100 Episods Avg Reward is ==> 122.75702696841249\n",
      "Episode * 1340 * Steps 232  * Episodic Reward is ==> 240.3207415970388 * Lastest 100 Episods Avg Reward is ==> 136.1047742745169\n",
      "Episode * 1350 * Steps 94  * Episodic Reward is ==> 16.277800670789176 * Lastest 100 Episods Avg Reward is ==> 135.7054830851676\n",
      "Episode * 1360 * Steps 254  * Episodic Reward is ==> 269.993906469031 * Lastest 100 Episods Avg Reward is ==> 144.52514003342085\n",
      "Episode * 1370 * Steps 99  * Episodic Reward is ==> 10.461204803376347 * Lastest 100 Episods Avg Reward is ==> 136.9432120120805\n",
      "Episode * 1380 * Steps 103  * Episodic Reward is ==> 28.281782288868612 * Lastest 100 Episods Avg Reward is ==> 139.5545774617861\n",
      "Episode * 1390 * Steps 97  * Episodic Reward is ==> 36.28624527095997 * Lastest 100 Episods Avg Reward is ==> 140.20305309798135\n",
      "Episode * 1400 * Steps 75  * Episodic Reward is ==> -11.418223740276304 * Lastest 100 Episods Avg Reward is ==> 134.54678288897085\n",
      "Episode * 1410 * Steps 102  * Episodic Reward is ==> 65.35574328075668 * Lastest 100 Episods Avg Reward is ==> 125.13447143207662\n",
      "Episode * 1420 * Steps 107  * Episodic Reward is ==> 62.25334049559257 * Lastest 100 Episods Avg Reward is ==> 111.06322842108301\n",
      "Episode * 1430 * Steps 214  * Episodic Reward is ==> 252.01089276362262 * Lastest 100 Episods Avg Reward is ==> 101.84308488905916\n",
      "Episode * 1440 * Steps 98  * Episodic Reward is ==> 19.361857878272176 * Lastest 100 Episods Avg Reward is ==> 84.0285666536091\n",
      "Episode * 1450 * Steps 117  * Episodic Reward is ==> 55.54771519084997 * Lastest 100 Episods Avg Reward is ==> 75.87277839278596\n",
      "Episode * 1460 * Steps 108  * Episodic Reward is ==> 51.79702446234097 * Lastest 100 Episods Avg Reward is ==> 58.777057116375325\n",
      "Episode * 1470 * Steps 265  * Episodic Reward is ==> 248.39985079877994 * Lastest 100 Episods Avg Reward is ==> 55.07289162038685\n",
      "Episode * 1480 * Steps 169  * Episodic Reward is ==> 253.87423450066518 * Lastest 100 Episods Avg Reward is ==> 61.188890575475945\n",
      "Episode * 1490 * Steps 273  * Episodic Reward is ==> 204.19128177477518 * Lastest 100 Episods Avg Reward is ==> 76.56621734056833\n",
      "Episode * 1500 * Steps 206  * Episodic Reward is ==> 245.14584914809802 * Lastest 100 Episods Avg Reward is ==> 94.42103492365575\n",
      "Episode * 1510 * Steps 500  * Episodic Reward is ==> 56.99386528024589 * Lastest 100 Episods Avg Reward is ==> 105.05615137916828\n",
      "Episode * 1520 * Steps 124  * Episodic Reward is ==> 45.52973312953549 * Lastest 100 Episods Avg Reward is ==> 112.80193094178108\n",
      "Episode * 1530 * Steps 187  * Episodic Reward is ==> 275.2122898100531 * Lastest 100 Episods Avg Reward is ==> 127.12424284040183\n",
      "Episode * 1540 * Steps 241  * Episodic Reward is ==> 313.84744834507785 * Lastest 100 Episods Avg Reward is ==> 139.70791163699204\n",
      "Episode * 1550 * Steps 249  * Episodic Reward is ==> 269.77022322787457 * Lastest 100 Episods Avg Reward is ==> 159.22949816383513\n",
      "Episode * 1560 * Steps 246  * Episodic Reward is ==> 285.50017289020457 * Lastest 100 Episods Avg Reward is ==> 180.09022169995617\n",
      "Episode * 1570 * Steps 192  * Episodic Reward is ==> 303.4234642335022 * Lastest 100 Episods Avg Reward is ==> 198.91004271300392\n",
      "Episode * 1580 * Steps 198  * Episodic Reward is ==> 313.10894789254934 * Lastest 100 Episods Avg Reward is ==> 206.24385530032308\n",
      "Episode * 1590 * Steps 500  * Episodic Reward is ==> 131.51727924102445 * Lastest 100 Episods Avg Reward is ==> 209.7637307382205\n",
      "Episode * 1600 * Steps 181  * Episodic Reward is ==> 265.84621007981934 * Lastest 100 Episods Avg Reward is ==> 209.43581553090166\n",
      "Episode * 1610 * Steps 500  * Episodic Reward is ==> 159.73998915418355 * Lastest 100 Episods Avg Reward is ==> 219.099982743307\n",
      "Episode * 1620 * Steps 241  * Episodic Reward is ==> 303.559871401028 * Lastest 100 Episods Avg Reward is ==> 228.9675446975055\n",
      "Episode * 1630 * Steps 192  * Episodic Reward is ==> 264.4405303415102 * Lastest 100 Episods Avg Reward is ==> 227.06924883883582\n",
      "Episode * 1640 * Steps 500  * Episodic Reward is ==> 112.4879540668099 * Lastest 100 Episods Avg Reward is ==> 235.45601183949347\n",
      "Episode * 1650 * Steps 413  * Episodic Reward is ==> 254.87306218412172 * Lastest 100 Episods Avg Reward is ==> 237.5164011718184\n",
      "Episode * 1660 * Steps 184  * Episodic Reward is ==> 255.1346330961227 * Lastest 100 Episods Avg Reward is ==> 235.94465793085476\n",
      "Episode * 1670 * Steps 187  * Episodic Reward is ==> 273.21743425316834 * Lastest 100 Episods Avg Reward is ==> 237.20945539528864\n",
      "Episode * 1680 * Steps 216  * Episodic Reward is ==> 312.5954378664185 * Lastest 100 Episods Avg Reward is ==> 244.48308047820296\n",
      "Episode * 1690 * Steps 251  * Episodic Reward is ==> 281.38859056814067 * Lastest 100 Episods Avg Reward is ==> 240.76318776207145\n",
      "Episode * 1700 * Steps 109  * Episodic Reward is ==> 33.6899352399239 * Lastest 100 Episods Avg Reward is ==> 236.15568698316517\n",
      "Episode * 1710 * Steps 128  * Episodic Reward is ==> 38.48730726702925 * Lastest 100 Episods Avg Reward is ==> 233.88310750730332\n",
      "Episode * 1720 * Steps 205  * Episodic Reward is ==> 262.7368332497771 * Lastest 100 Episods Avg Reward is ==> 234.05505304207716\n",
      "Episode * 1730 * Steps 190  * Episodic Reward is ==> 280.80460088728375 * Lastest 100 Episods Avg Reward is ==> 232.37301575290837\n",
      "Episode * 1740 * Steps 210  * Episodic Reward is ==> 288.5720960118251 * Lastest 100 Episods Avg Reward is ==> 223.45389978674407\n",
      "Episode * 1750 * Steps 500  * Episodic Reward is ==> 51.66293476205128 * Lastest 100 Episods Avg Reward is ==> 208.96804878156226\n",
      "Episode * 1760 * Steps 500  * Episodic Reward is ==> 149.86993973700578 * Lastest 100 Episods Avg Reward is ==> 207.40287940834853\n",
      "Episode * 1770 * Steps 195  * Episodic Reward is ==> 274.23951625895984 * Lastest 100 Episods Avg Reward is ==> 209.76443761809202\n",
      "Episode * 1780 * Steps 204  * Episodic Reward is ==> 264.80599350588307 * Lastest 100 Episods Avg Reward is ==> 202.42653208658638\n",
      "Episode * 1790 * Steps 173  * Episodic Reward is ==> 298.23506620113335 * Lastest 100 Episods Avg Reward is ==> 202.89632877866683\n",
      "Episode * 1800 * Steps 196  * Episodic Reward is ==> 277.20749483444126 * Lastest 100 Episods Avg Reward is ==> 201.44092927142788\n",
      "Episode * 1810 * Steps 500  * Episodic Reward is ==> 133.5764883812972 * Lastest 100 Episods Avg Reward is ==> 195.9542920406706\n",
      "Episode * 1820 * Steps 231  * Episodic Reward is ==> 247.8572739578026 * Lastest 100 Episods Avg Reward is ==> 194.21173276546452\n",
      "Episode * 1830 * Steps 112  * Episodic Reward is ==> 39.644649707130924 * Lastest 100 Episods Avg Reward is ==> 194.0979167134085\n",
      "Episode * 1840 * Steps 190  * Episodic Reward is ==> 289.93641393004077 * Lastest 100 Episods Avg Reward is ==> 205.16261753012387\n",
      "Episode * 1850 * Steps 212  * Episodic Reward is ==> 254.36326141905212 * Lastest 100 Episods Avg Reward is ==> 220.55203231533943\n",
      "Episode * 1860 * Steps 191  * Episodic Reward is ==> 312.1159382565262 * Lastest 100 Episods Avg Reward is ==> 221.53810882331055\n",
      "Episode * 1870 * Steps 500  * Episodic Reward is ==> 13.691409216454064 * Lastest 100 Episods Avg Reward is ==> 215.03132296170668\n",
      "Episode * 1880 * Steps 171  * Episodic Reward is ==> 258.60496639768905 * Lastest 100 Episods Avg Reward is ==> 218.71135771780436\n",
      "Episode * 1890 * Steps 187  * Episodic Reward is ==> 232.98003227304793 * Lastest 100 Episods Avg Reward is ==> 215.90784699474543\n",
      "Episode * 1900 * Steps 268  * Episodic Reward is ==> 228.32924349518208 * Lastest 100 Episods Avg Reward is ==> 224.2183590733096\n",
      "Episode * 1910 * Steps 207  * Episodic Reward is ==> 286.8602709981261 * Lastest 100 Episods Avg Reward is ==> 230.65006697212127\n",
      "Episode * 1920 * Steps 203  * Episodic Reward is ==> 312.7559916879509 * Lastest 100 Episods Avg Reward is ==> 238.66789701464754\n",
      "Episode * 1930 * Steps 200  * Episodic Reward is ==> 259.35537159224185 * Lastest 100 Episods Avg Reward is ==> 241.42620251991346\n",
      "Episode * 1940 * Steps 500  * Episodic Reward is ==> -38.47146465628581 * Lastest 100 Episods Avg Reward is ==> 233.46454687362063\n",
      "Episode * 1950 * Steps 218  * Episodic Reward is ==> 263.1413962335088 * Lastest 100 Episods Avg Reward is ==> 226.94611537949393\n",
      "Episode * 1960 * Steps 277  * Episodic Reward is ==> 313.0488336757979 * Lastest 100 Episods Avg Reward is ==> 226.96597866155054\n",
      "Episode * 1970 * Steps 124  * Episodic Reward is ==> 77.03680869462136 * Lastest 100 Episods Avg Reward is ==> 229.9744081249346\n",
      "Episode * 1980 * Steps 222  * Episodic Reward is ==> 281.7134531788895 * Lastest 100 Episods Avg Reward is ==> 227.6787558129018\n",
      "Episode * 1990 * Steps 223  * Episodic Reward is ==> 263.650847806726 * Lastest 100 Episods Avg Reward is ==> 229.33988215787923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_15de1ce7-b8c9-43e9-aec9-5f2577cd78b3\", \"ppo_20210405_173212.csv\", 91650)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ep in range(max_episodes):\n",
    "    episodic_reward = 0\n",
    "    state = gym_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    gaes = []\n",
    "    states = []\n",
    "    actions = []\n",
    "\n",
    "    while not done and steps < max_step:\n",
    "        with torch.no_grad():\n",
    "            states.append(state)\n",
    "            mu, var = actor_model(torch.tensor(state))\n",
    "            mu = mu.detach().numpy()\n",
    "            std_dev = torch.sqrt(var).detach().numpy()\n",
    "            action = np.clip(np.random.normal(mu, std_dev), lower_bound, upper_bound).flatten()\n",
    "            actions.append(action)\n",
    "        \n",
    "        next_state, reward, done, info = gym_env.step(action)\n",
    "        gaes.append(reward)\n",
    "        if len(gaes)>1:\n",
    "            for i in range(len(gaes)-1):\n",
    "                gaes[i]+=(lambda_advantage**(steps-i))*reward\n",
    "\n",
    "        episodic_reward += reward\n",
    "        state = next_state\n",
    "        steps+=1\n",
    "    gaes = torch.tensor(gaes, dtype=torch.float32)\n",
    "    states = torch.tensor(states, dtype=torch.float32)\n",
    "    actions = torch.tensor(actions, dtype=torch.float32)\n",
    "\n",
    "    values = critic_model(states)\n",
    "    values = torch.reshape(values,gaes.shape)\n",
    "    psi = gaes - values.detach()\n",
    "    means, sigmas = actor_model(states)\n",
    "    dist_v1 = normal_pdf(actions[:,0], means[:,0], sigmas[:,0])\n",
    "    dist_v2 = normal_pdf(actions[:,1], means[:,1], sigmas[:,1])\n",
    "    pi = dist_v1 * dist_v2\n",
    "    old_pi = pi.detach()\n",
    "\n",
    "    for n in range(n_updates):\n",
    "        critic_model.train()\n",
    "        values = critic_model(states)\n",
    "        values = torch.reshape(values,gaes.shape)\n",
    "        means, sigmas = actor_model(states)\n",
    "        dist_v1 = normal_pdf(actions[:,0], means[:,0], sigmas[:,0])\n",
    "        dist_v2 = normal_pdf(actions[:,1], means[:,1], sigmas[:,1])\n",
    "        pi = dist_v1 * dist_v2\n",
    "        critic_loss = nn.functional.mse_loss(values, gaes.detach())\n",
    "        optimizer_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(critic_model.parameters(), max_norm=1.0)\n",
    "        optimizer_critic.step()\n",
    "        r = torch.div(pi, old_pi)\n",
    "        c_eps = torch.max(torch.min(r, torch.tensor(1+epsilon, dtype=torch.float32)), torch.tensor(1-epsilon, dtype=torch.float32))\n",
    "        psi = psi.detach()\n",
    "        actor_model.train()\n",
    "        actor_loss = -torch.mean(torch.min(r*psi,c_eps*psi))\n",
    "        optimizer_actor.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(actor_model.parameters(), max_norm=1.0)\n",
    "        optimizer_actor.step()\n",
    "\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "    ep_steps_list.append(steps)\n",
    "    avg_reward = np.mean(ep_reward_list[-100:])\n",
    "    avg_reward_list.append(avg_reward)\n",
    "    \n",
    "    if ep%10 == 0:\n",
    "        print(f\"Episode * {ep} * Steps {steps}  * Episodic Reward is ==> {episodic_reward} * Lastest 100 Episods Avg Reward is ==> {avg_reward}\")\n",
    "\n",
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()\n",
    "\n",
    "content = {\"ep_reward\":ep_reward_list,\"avg_reward\":avg_reward_list, \"steps\":ep_steps_list}\n",
    "df = pd.DataFrame(content)\n",
    "df.to_csv(f'ppo_{date_time}.csv') \n",
    "files.download(f'ppo_{date_time}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEO-kLPoiurL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PPO_pytorch_continous.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
