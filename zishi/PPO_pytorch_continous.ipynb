{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P4ocnfC77Beq",
        "outputId": "6ce40111-f12c-4ba4-d227-c0eecece71df"
      },
      "source": [
        "!pip install --upgrade --force-reinstall box2d-py\n",
        "!pip install --upgrade --force-reinstall gym[Box_2D]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/34/da5393985c3ff9a76351df6127c275dcb5749ae0abbe8d5210f06d97405d/box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448kB)\n",
            "\r\u001b[K     |▊                               | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 13.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 5.2MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Collecting gym[Box_2D]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/f2/e7ee20bf02b2d02263becba1c5ec4203fef7cfbd57759e040e51307173f4/gym-0.18.0.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 4.5MB/s \n",
            "\u001b[33m  WARNING: gym 0.18.0 does not provide the extra 'box_2d'\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/91/ee427c42957f8c4cbe477bf4f8b7f608e003a17941e509d1777e58648cb3/scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4MB 141kB/s \n",
            "\u001b[?25hCollecting numpy>=1.10.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8a/064b4077e3d793f877e3b77aa64f56fa49a4d37236a53f78ee28be009a16/numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 145kB/s \n",
            "\u001b[?25hCollecting pyglet<=1.5.0,>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.1MB/s \n",
            "\u001b[?25hCollecting Pillow<=7.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/f2/6722dd0c22e3a143ac792ccb2424924ac72af4adea756b1165b4cad50da7/Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 47.8MB/s \n",
            "\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Collecting future\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 32.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.18.0-cp37-none-any.whl size=1656447 sha256=906a646dacf40b52cb5b8865da6ef7c1263ce7675a7807988e2574b7a1e6e50a\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/85/3b/480b828a4a697b37392740a040b8989f729d952b4e441a1877\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=34de964cb635863e37240a3936e96eb5c40bf55c3484de6db806b3867a163714\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built gym future\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, scipy, future, pyglet, Pillow, cloudpickle, gym\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed Pillow-7.2.0 cloudpickle-1.6.0 future-0.18.2 gym-0.18.0 numpy-1.20.1 pyglet-1.5.0 scipy-1.6.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IHFmodk7Hv4"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
		"import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.distributions.normal as tdn\n",
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmVV_7S_7WMY"
      },
      "source": [
        "def normal_pdf(x,mu,sigma):\n",
        "    dist = tdn.Normal(loc=mu, scale=torch.sqrt(sigma))\n",
        "    return dist.log_prob(x).exp()"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p815V-lC5A7"
      },
      "source": [
        "class actor(nn.Module):\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        super(actor, self).__init__()\n",
        "        self.inputs = nn.Linear(input_shape, 512)\n",
        "        self.input_activation = nn.ReLU()\n",
        "        self.input_mean = nn.Linear(512, 256)\n",
        "        self.output_mean = nn.Linear(256, output_shape)\n",
        "        self.actor_mean = nn.Tanh()\n",
        "        self.input_sigma = nn.Linear(512, 256)\n",
        "        self.output_sigma = nn.Linear(256, output_shape)\n",
        "        self.actor_sigma = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lvl1 = self.inputs(x)\n",
        "        lvl1 = self.input_activation(lvl1)\n",
        "\n",
        "        means = self.input_mean(lvl1)\n",
        "        means = self.input_activation(means)\n",
        "        means = self.output_mean(means)\n",
        "        means = self.actor_mean(means)\n",
        "\n",
        "        sigmas = self.input_sigma(lvl1)\n",
        "        sigmas = self.input_activation(sigmas)\n",
        "        sigmas = self.output_sigma(sigmas)\n",
        "        sigmas = self.actor_sigma(sigmas)\n",
        "        return means, sigmas\n",
        "\n",
        "\n",
        "class critic(nn.Module):\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        super(critic, self).__init__()\n",
        "\n",
        "        self.inputs = nn.Linear(input_shape, 512)\n",
        "        self.input_activation = nn.ReLU()\n",
        "        self.layers = nn.Linear(512, 256)\n",
        "        self.output = nn.Linear(256, output_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lvl = self.inputs(x)\n",
        "        lvl = self.input_activation(lvl)\n",
        "        lvl = self.layers(lvl)\n",
        "        lvl = self.input_activation(lvl)\n",
        "        outputs = self.output(lvl)\n",
        "        return outputs\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZUIlb7iF5br"
      },
      "source": [
        "problem = \"LunarLanderContinuous-v2\"\n",
        "RANDOM_SEEDS = 123\n",
        "gym_env = gym.make(problem)\n",
        "gym_env.seed(RANDOM_SEEDS)\n",
        "\n",
        "gym_env.reset()\n",
        "\n",
        "max_episodes = 2000\n",
        "gamma = 0.99\n",
        "state_shape = gym_env.observation_space.shape[0]\n",
        "action_dim = gym_env.action_space.shape[0]\n",
        "upper_bound = gym_env.action_space.high[0]\n",
        "lower_bound = gym_env.action_space.low[0]\n",
        "epsilon=0.2\n",
        "n_updates=10 \n",
        "lr_critic=1e-3\n",
        "lr_actor=1e-5\n",
        "memory_size=2**14\n",
        "\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%Y%m%d_%H%M%S\")"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUka9KiuGvys"
      },
      "source": [
        "ep_reward_list = []\n",
        "ep_steps_list = []\n",
        "avg_reward_list = []"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqSRHYP3Hhlq"
      },
      "source": [
        "actor_model = actor(state_shape, action_dim)\n",
        "critic_model = critic(state_shape, 1)\n",
        "optimizer_actor = optim.Adam(actor_model.parameters(), lr=lr_actor)\n",
        "optimizer_critic = optim.Adam(critic_model.parameters(), lr=lr_critic)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iNyxZDMkIN8T",
        "outputId": "9feecef6-c85f-4a7a-864c-c3b5f744e35a"
      },
      "source": [
        "for ep in range(max_episodes):\n",
        "    buffer = ReplayBuffer(memory_size=memory_size)\n",
        "    episodic_reward = 0\n",
        "    state = gym_env.reset()\n",
        "    done = False\n",
        "    steps = 0\n",
        "    gaes = []\n",
        "    states = []\n",
        "    actions = []\n",
        "\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            states.append(state)\n",
        "            mu, var = actor_model(torch.tensor(state))\n",
        "            mu = mu.detach().numpy()\n",
        "            std_dev = torch.sqrt(var).detach().numpy()\n",
        "            action = np.clip(np.random.normal(mu, std_dev), lower_bound, upper_bound).flatten()\n",
        "            actions.append(action)\n",
        "        \n",
        "        next_state, reward, done, info = gym_env.step(action)\n",
        "        gaes.append(reward)\n",
        "        if len(gaes)>1:\n",
        "            for i in range(len(gaes)-1):\n",
        "                gaes[i]+=(gamma**(steps-i))*reward\n",
        "\n",
        "        episodic_reward += reward\n",
        "        state = next_state\n",
        "        steps+=1\n",
        "    gaes = torch.tensor(gaes, dtype=torch.float32)\n",
        "    states = torch.tensor(states, dtype=torch.float32)\n",
        "    actions = torch.tensor(actions, dtype=torch.float32)\n",
        "\n",
        "    values = critic_model(states)\n",
        "    values = torch.reshape(values,gaes.shape)\n",
        "    psi = gaes - values.detach()\n",
        "    means, sigmas = actor_model(states)\n",
        "    dist_v1 = normal_pdf(actions[:,0], means[:,0], sigmas[:,0])\n",
        "    dist_v2 = normal_pdf(actions[:,1], means[:,1], sigmas[:,1])\n",
        "    pi = dist_v1 * dist_v2\n",
        "    old_pi = pi.detach()\n",
        "\n",
        "    for n in range(n_updates):\n",
        "        critic_model.train()\n",
        "        values = critic_model(states)\n",
        "        values = torch.reshape(values,gaes.shape)\n",
        "        means, sigmas = actor_model(states)\n",
        "        dist_v1 = normal_pdf(actions[:,0], means[:,0], sigmas[:,0])\n",
        "        dist_v2 = normal_pdf(actions[:,1], means[:,1], sigmas[:,1])\n",
        "        pi = dist_v1 * dist_v2\n",
        "        critic_loss = nn.functional.mse_loss(values, gaes.detach())\n",
        "        optimizer_critic.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(critic_model.parameters(), max_norm=1.0)\n",
        "        optimizer_critic.step()\n",
        "        r = torch.div(pi, old_pi)\n",
        "        c_eps = torch.max(torch.min(r, torch.tensor(1+epsilon, dtype=torch.float32)), torch.tensor(1-epsilon, dtype=torch.float32))\n",
        "        psi = psi.detach()\n",
        "        actor_model.train()\n",
        "        actor_loss = -torch.mean(torch.min(r*psi,c_eps*psi))\n",
        "        optimizer_actor.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(actor_model.parameters(), max_norm=1.0)\n",
        "        optimizer_actor.step()\n",
        "\n",
        "    ep_reward_list.append(episodic_reward)\n",
        "    ep_steps_list.append(steps)\n",
        "    avg_reward = np.mean(ep_reward_list[-100:])\n",
        "    avg_reward_list.append(avg_reward)\n",
        "    \n",
        "    if ep%10 == 0:\n",
        "        print(f\"Episode * {ep} * Steps {steps}  * Episodic Reward is ==> {episodic_reward} * Lastest 100 Episods Avg Reward is ==> {avg_reward}\")\n",
        "\n",
        "plt.plot(avg_reward_list)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
        "plt.show()\n",
        "\n",
        "content = {\"ep_reward\":ep_reward_list,\"avg_reward\":avg_reward_list, \"steps\":ep_steps_list}\n",
        "df = pd.DataFrame(content)\n",
        "df.to_csv(f'ppo_{date_time}.csv') \n",
        "files.download(f'ppo_{date_time}.csv')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode * 0 * Steps 94  * Episodic Reward is ==> -310.2798248389545 * Lastest 100 Episods Avg Reward is ==> -310.2798248389545\n",
            "Episode * 10 * Steps 114  * Episodic Reward is ==> -171.72374728082542 * Lastest 100 Episods Avg Reward is ==> -347.08232283336446\n",
            "Episode * 20 * Steps 133  * Episodic Reward is ==> -200.13852391205637 * Lastest 100 Episods Avg Reward is ==> -308.97448301480273\n",
            "Episode * 30 * Steps 84  * Episodic Reward is ==> -60.007735890590624 * Lastest 100 Episods Avg Reward is ==> -275.51148118687735\n",
            "Episode * 40 * Steps 82  * Episodic Reward is ==> -80.33173301822221 * Lastest 100 Episods Avg Reward is ==> -240.64257504611234\n",
            "Episode * 50 * Steps 74  * Episodic Reward is ==> -108.78616472707387 * Lastest 100 Episods Avg Reward is ==> -231.37195667826984\n",
            "Episode * 60 * Steps 114  * Episodic Reward is ==> -96.92484207713721 * Lastest 100 Episods Avg Reward is ==> -212.83053266715098\n",
            "Episode * 70 * Steps 83  * Episodic Reward is ==> -159.5651626834253 * Lastest 100 Episods Avg Reward is ==> -207.5540271858675\n",
            "Episode * 80 * Steps 77  * Episodic Reward is ==> -194.44527312357496 * Lastest 100 Episods Avg Reward is ==> -197.229310335692\n",
            "Episode * 90 * Steps 123  * Episodic Reward is ==> -87.32402942334927 * Lastest 100 Episods Avg Reward is ==> -188.15235000789602\n",
            "Episode * 100 * Steps 158  * Episodic Reward is ==> -238.12015999300303 * Lastest 100 Episods Avg Reward is ==> -182.87801916051572\n",
            "Episode * 110 * Steps 108  * Episodic Reward is ==> -55.60100189821456 * Lastest 100 Episods Avg Reward is ==> -160.99156087119513\n",
            "Episode * 120 * Steps 104  * Episodic Reward is ==> -134.22043607094946 * Lastest 100 Episods Avg Reward is ==> -148.74500805817522\n",
            "Episode * 130 * Steps 99  * Episodic Reward is ==> -128.10460206495128 * Lastest 100 Episods Avg Reward is ==> -145.07744529827502\n",
            "Episode * 140 * Steps 97  * Episodic Reward is ==> -136.53045961510122 * Lastest 100 Episods Avg Reward is ==> -142.71111777591403\n",
            "Episode * 150 * Steps 133  * Episodic Reward is ==> -187.0729352239814 * Lastest 100 Episods Avg Reward is ==> -137.07334374418562\n",
            "Episode * 160 * Steps 108  * Episodic Reward is ==> -189.74836677102297 * Lastest 100 Episods Avg Reward is ==> -134.9778703901794\n",
            "Episode * 170 * Steps 149  * Episodic Reward is ==> -107.78979524154198 * Lastest 100 Episods Avg Reward is ==> -129.20536571589227\n",
            "Episode * 180 * Steps 161  * Episodic Reward is ==> -86.19224969401893 * Lastest 100 Episods Avg Reward is ==> -127.8407887669735\n",
            "Episode * 190 * Steps 94  * Episodic Reward is ==> -46.805730508397374 * Lastest 100 Episods Avg Reward is ==> -122.30500070237035\n",
            "Episode * 200 * Steps 172  * Episodic Reward is ==> -287.4825002972658 * Lastest 100 Episods Avg Reward is ==> -121.36205185577538\n",
            "Episode * 210 * Steps 255  * Episodic Reward is ==> -222.41701820986208 * Lastest 100 Episods Avg Reward is ==> -120.69785763575412\n",
            "Episode * 220 * Steps 106  * Episodic Reward is ==> -0.1350187765124531 * Lastest 100 Episods Avg Reward is ==> -122.05459860759414\n",
            "Episode * 230 * Steps 159  * Episodic Reward is ==> -52.354046443526 * Lastest 100 Episods Avg Reward is ==> -114.94690615197509\n",
            "Episode * 240 * Steps 224  * Episodic Reward is ==> -368.8470249724646 * Lastest 100 Episods Avg Reward is ==> -119.38967763613638\n",
            "Episode * 250 * Steps 174  * Episodic Reward is ==> -122.24846784856214 * Lastest 100 Episods Avg Reward is ==> -118.02351069545676\n",
            "Episode * 260 * Steps 158  * Episodic Reward is ==> -103.5908161794208 * Lastest 100 Episods Avg Reward is ==> -117.09895384683765\n",
            "Episode * 270 * Steps 516  * Episodic Reward is ==> -234.7467748539964 * Lastest 100 Episods Avg Reward is ==> -113.34837819678451\n",
            "Episode * 280 * Steps 97  * Episodic Reward is ==> -68.95960378102419 * Lastest 100 Episods Avg Reward is ==> -109.56390761023303\n",
            "Episode * 290 * Steps 169  * Episodic Reward is ==> -69.09296413812291 * Lastest 100 Episods Avg Reward is ==> -113.48019924386921\n",
            "Episode * 300 * Steps 108  * Episodic Reward is ==> -65.86374648588561 * Lastest 100 Episods Avg Reward is ==> -101.82216952380766\n",
            "Episode * 310 * Steps 146  * Episodic Reward is ==> -11.630594030085703 * Lastest 100 Episods Avg Reward is ==> -94.66839236720136\n",
            "Episode * 320 * Steps 169  * Episodic Reward is ==> 14.621480987017094 * Lastest 100 Episods Avg Reward is ==> -85.12008765146817\n",
            "Episode * 330 * Steps 139  * Episodic Reward is ==> -28.067719354667787 * Lastest 100 Episods Avg Reward is ==> -90.09800747410445\n",
            "Episode * 340 * Steps 269  * Episodic Reward is ==> -230.12875150664343 * Lastest 100 Episods Avg Reward is ==> -82.18300557282339\n",
            "Episode * 350 * Steps 136  * Episodic Reward is ==> -65.33420640853859 * Lastest 100 Episods Avg Reward is ==> -76.20824629882793\n",
            "Episode * 360 * Steps 133  * Episodic Reward is ==> -45.2683281972936 * Lastest 100 Episods Avg Reward is ==> -69.31331206507807\n",
            "Episode * 370 * Steps 599  * Episodic Reward is ==> -200.717386624563 * Lastest 100 Episods Avg Reward is ==> -71.39821699008827\n",
            "Episode * 380 * Steps 129  * Episodic Reward is ==> -2.631559245390477 * Lastest 100 Episods Avg Reward is ==> -64.17153796710468\n",
            "Episode * 390 * Steps 179  * Episodic Reward is ==> -37.24266894561057 * Lastest 100 Episods Avg Reward is ==> -59.567343485981354\n",
            "Episode * 400 * Steps 171  * Episodic Reward is ==> 39.79121129640441 * Lastest 100 Episods Avg Reward is ==> -64.78331253401342\n",
            "Episode * 410 * Steps 167  * Episodic Reward is ==> 25.45311384398738 * Lastest 100 Episods Avg Reward is ==> -61.239439578075874\n",
            "Episode * 420 * Steps 171  * Episodic Reward is ==> -12.547131775220663 * Lastest 100 Episods Avg Reward is ==> -60.739070354552986\n",
            "Episode * 430 * Steps 149  * Episodic Reward is ==> -4.597388163667233 * Lastest 100 Episods Avg Reward is ==> -50.54440422581544\n",
            "Episode * 440 * Steps 155  * Episodic Reward is ==> -13.203736473424016 * Lastest 100 Episods Avg Reward is ==> -44.57372881426673\n",
            "Episode * 450 * Steps 1000  * Episodic Reward is ==> -17.638233412959472 * Lastest 100 Episods Avg Reward is ==> -44.057879176427484\n",
            "Episode * 460 * Steps 194  * Episodic Reward is ==> -34.88506204021553 * Lastest 100 Episods Avg Reward is ==> -51.921089629238466\n",
            "Episode * 470 * Steps 143  * Episodic Reward is ==> 61.49691557477587 * Lastest 100 Episods Avg Reward is ==> -48.30936752862755\n",
            "Episode * 480 * Steps 249  * Episodic Reward is ==> -165.70923380916668 * Lastest 100 Episods Avg Reward is ==> -58.65162731964782\n",
            "Episode * 490 * Steps 144  * Episodic Reward is ==> -9.100391668786003 * Lastest 100 Episods Avg Reward is ==> -62.0066721771582\n",
            "Episode * 500 * Steps 932  * Episodic Reward is ==> -238.5076262986192 * Lastest 100 Episods Avg Reward is ==> -58.475200939689245\n",
            "Episode * 510 * Steps 639  * Episodic Reward is ==> -309.83071099866504 * Lastest 100 Episods Avg Reward is ==> -69.87564209437264\n",
            "Episode * 520 * Steps 162  * Episodic Reward is ==> 14.745735593638997 * Lastest 100 Episods Avg Reward is ==> -70.34971764489504\n",
            "Episode * 530 * Steps 1000  * Episodic Reward is ==> -27.42671045975255 * Lastest 100 Episods Avg Reward is ==> -68.58195732177353\n",
            "Episode * 540 * Steps 162  * Episodic Reward is ==> -4.698222064613347 * Lastest 100 Episods Avg Reward is ==> -69.50605036239843\n",
            "Episode * 550 * Steps 1000  * Episodic Reward is ==> -21.842597838390628 * Lastest 100 Episods Avg Reward is ==> -65.36657086288191\n",
            "Episode * 560 * Steps 137  * Episodic Reward is ==> 23.69948450473734 * Lastest 100 Episods Avg Reward is ==> -60.13148184455544\n",
            "Episode * 570 * Steps 312  * Episodic Reward is ==> -57.506512837931496 * Lastest 100 Episods Avg Reward is ==> -55.692910900090666\n",
            "Episode * 580 * Steps 340  * Episodic Reward is ==> -103.97107214835194 * Lastest 100 Episods Avg Reward is ==> -51.20364600775773\n",
            "Episode * 590 * Steps 315  * Episodic Reward is ==> -87.47861954759152 * Lastest 100 Episods Avg Reward is ==> -44.81835150571671\n",
            "Episode * 600 * Steps 135  * Episodic Reward is ==> -9.840097503937187 * Lastest 100 Episods Avg Reward is ==> -40.570452415036385\n",
            "Episode * 610 * Steps 1000  * Episodic Reward is ==> 10.865694449380882 * Lastest 100 Episods Avg Reward is ==> -27.959001012416383\n",
            "Episode * 620 * Steps 1000  * Episodic Reward is ==> 65.6868759882827 * Lastest 100 Episods Avg Reward is ==> -25.890680017194164\n",
            "Episode * 630 * Steps 159  * Episodic Reward is ==> 7.067106788357378 * Lastest 100 Episods Avg Reward is ==> -23.643421452413605\n",
            "Episode * 640 * Steps 153  * Episodic Reward is ==> 18.829583372596062 * Lastest 100 Episods Avg Reward is ==> -17.716706080671692\n",
            "Episode * 650 * Steps 150  * Episodic Reward is ==> 36.29586488477514 * Lastest 100 Episods Avg Reward is ==> -12.960992729602513\n",
            "Episode * 660 * Steps 1000  * Episodic Reward is ==> 41.24991210264708 * Lastest 100 Episods Avg Reward is ==> -5.25827192270588\n",
            "Episode * 670 * Steps 1000  * Episodic Reward is ==> 20.92186818908767 * Lastest 100 Episods Avg Reward is ==> -3.720994030175859\n",
            "Episode * 680 * Steps 1000  * Episodic Reward is ==> 119.6438970889731 * Lastest 100 Episods Avg Reward is ==> 5.484686495267117\n",
            "Episode * 690 * Steps 1000  * Episodic Reward is ==> 52.72330399768419 * Lastest 100 Episods Avg Reward is ==> 13.710900772749833\n",
            "Episode * 700 * Steps 140  * Episodic Reward is ==> 6.200913461833508 * Lastest 100 Episods Avg Reward is ==> 14.892758782247947\n",
            "Episode * 710 * Steps 1000  * Episodic Reward is ==> 169.20655079703246 * Lastest 100 Episods Avg Reward is ==> 26.11069372784933\n",
            "Episode * 720 * Steps 1000  * Episodic Reward is ==> 79.57365375654263 * Lastest 100 Episods Avg Reward is ==> 31.139521762392906\n",
            "Episode * 730 * Steps 207  * Episodic Reward is ==> 7.068389125312379 * Lastest 100 Episods Avg Reward is ==> 36.914326492686335\n",
            "Episode * 740 * Steps 293  * Episodic Reward is ==> 248.321068475324 * Lastest 100 Episods Avg Reward is ==> 34.67861034518106\n",
            "Episode * 750 * Steps 386  * Episodic Reward is ==> -130.45062788218672 * Lastest 100 Episods Avg Reward is ==> 41.237106441691694\n",
            "Episode * 760 * Steps 236  * Episodic Reward is ==> 24.488877551687622 * Lastest 100 Episods Avg Reward is ==> 51.02251474702226\n",
            "Episode * 770 * Steps 381  * Episodic Reward is ==> -224.7244408738439 * Lastest 100 Episods Avg Reward is ==> 52.59420392067058\n",
            "Episode * 780 * Steps 1000  * Episodic Reward is ==> 125.18287151905281 * Lastest 100 Episods Avg Reward is ==> 63.457171526442224\n",
            "Episode * 790 * Steps 404  * Episodic Reward is ==> 255.47990286802306 * Lastest 100 Episods Avg Reward is ==> 76.88512120736529\n",
            "Episode * 800 * Steps 287  * Episodic Reward is ==> 269.07488118391575 * Lastest 100 Episods Avg Reward is ==> 98.14282196274752\n",
            "Episode * 810 * Steps 309  * Episodic Reward is ==> 173.64415564627268 * Lastest 100 Episods Avg Reward is ==> 96.35103408549492\n",
            "Episode * 820 * Steps 189  * Episodic Reward is ==> -21.76857097952592 * Lastest 100 Episods Avg Reward is ==> 100.13309740987432\n",
            "Episode * 830 * Steps 335  * Episodic Reward is ==> 255.01677964106486 * Lastest 100 Episods Avg Reward is ==> 106.55173210865695\n",
            "Episode * 840 * Steps 209  * Episodic Reward is ==> 44.56771616466901 * Lastest 100 Episods Avg Reward is ==> 109.03215392277448\n",
            "Episode * 850 * Steps 302  * Episodic Reward is ==> 275.95477433156435 * Lastest 100 Episods Avg Reward is ==> 120.52546020477776\n",
            "Episode * 860 * Steps 181  * Episodic Reward is ==> 31.485154804392067 * Lastest 100 Episods Avg Reward is ==> 116.43967628215434\n",
            "Episode * 870 * Steps 310  * Episodic Reward is ==> 274.7346508856838 * Lastest 100 Episods Avg Reward is ==> 126.14190586843169\n",
            "Episode * 880 * Steps 130  * Episodic Reward is ==> 32.110558573175695 * Lastest 100 Episods Avg Reward is ==> 113.67065924455365\n",
            "Episode * 890 * Steps 293  * Episodic Reward is ==> 189.07593119797392 * Lastest 100 Episods Avg Reward is ==> 98.15687178324987\n",
            "Episode * 900 * Steps 218  * Episodic Reward is ==> -182.6966969870037 * Lastest 100 Episods Avg Reward is ==> 83.66197984465529\n",
            "Episode * 910 * Steps 419  * Episodic Reward is ==> 274.21440735882857 * Lastest 100 Episods Avg Reward is ==> 87.52322195076549\n",
            "Episode * 920 * Steps 325  * Episodic Reward is ==> 254.53860821816968 * Lastest 100 Episods Avg Reward is ==> 93.15749921464793\n",
            "Episode * 930 * Steps 535  * Episodic Reward is ==> 277.1669587161608 * Lastest 100 Episods Avg Reward is ==> 96.16569581928323\n",
            "Episode * 940 * Steps 309  * Episodic Reward is ==> 274.92377860769966 * Lastest 100 Episods Avg Reward is ==> 95.87068393177346\n",
            "Episode * 950 * Steps 329  * Episodic Reward is ==> 273.1159231983171 * Lastest 100 Episods Avg Reward is ==> 93.84808841344504\n",
            "Episode * 960 * Steps 318  * Episodic Reward is ==> 305.0142457840604 * Lastest 100 Episods Avg Reward is ==> 100.51675574874572\n",
            "Episode * 970 * Steps 279  * Episodic Reward is ==> 237.60942242544448 * Lastest 100 Episods Avg Reward is ==> 106.52785269248783\n",
            "Episode * 980 * Steps 377  * Episodic Reward is ==> 278.9668086734797 * Lastest 100 Episods Avg Reward is ==> 116.91817477336224\n",
            "Episode * 990 * Steps 178  * Episodic Reward is ==> 21.810471097799905 * Lastest 100 Episods Avg Reward is ==> 123.29812115862647\n",
            "Episode * 1000 * Steps 188  * Episodic Reward is ==> 53.86816990269236 * Lastest 100 Episods Avg Reward is ==> 133.83433285056114\n",
            "Episode * 1010 * Steps 163  * Episodic Reward is ==> 31.611531783095955 * Lastest 100 Episods Avg Reward is ==> 128.65182959318975\n",
            "Episode * 1020 * Steps 184  * Episodic Reward is ==> 31.622458547574695 * Lastest 100 Episods Avg Reward is ==> 120.24061896318133\n",
            "Episode * 1030 * Steps 181  * Episodic Reward is ==> 57.886146411300984 * Lastest 100 Episods Avg Reward is ==> 115.992685656746\n",
            "Episode * 1040 * Steps 163  * Episodic Reward is ==> -25.798753072306397 * Lastest 100 Episods Avg Reward is ==> 116.9801088105706\n",
            "Episode * 1050 * Steps 179  * Episodic Reward is ==> 27.615669441206123 * Lastest 100 Episods Avg Reward is ==> 105.5809213537705\n",
            "Episode * 1060 * Steps 193  * Episodic Reward is ==> 12.560136914768023 * Lastest 100 Episods Avg Reward is ==> 93.66487300890242\n",
            "Episode * 1070 * Steps 219  * Episodic Reward is ==> 271.6667870698942 * Lastest 100 Episods Avg Reward is ==> 92.33364815753689\n",
            "Episode * 1080 * Steps 129  * Episodic Reward is ==> 24.84384278945106 * Lastest 100 Episods Avg Reward is ==> 92.39145082871987\n",
            "Episode * 1090 * Steps 331  * Episodic Reward is ==> 243.30958725949637 * Lastest 100 Episods Avg Reward is ==> 90.71234356341692\n",
            "Episode * 1100 * Steps 216  * Episodic Reward is ==> 277.37094104783944 * Lastest 100 Episods Avg Reward is ==> 81.04337616665572\n",
            "Episode * 1110 * Steps 250  * Episodic Reward is ==> 275.1814104590346 * Lastest 100 Episods Avg Reward is ==> 84.26642626898249\n",
            "Episode * 1120 * Steps 305  * Episodic Reward is ==> 233.44567703232343 * Lastest 100 Episods Avg Reward is ==> 93.82755335924375\n",
            "Episode * 1130 * Steps 336  * Episodic Reward is ==> 294.8037248637097 * Lastest 100 Episods Avg Reward is ==> 103.0113431451519\n",
            "Episode * 1140 * Steps 305  * Episodic Reward is ==> 292.20907462314676 * Lastest 100 Episods Avg Reward is ==> 113.65605934208486\n",
            "Episode * 1150 * Steps 236  * Episodic Reward is ==> -38.12830068887358 * Lastest 100 Episods Avg Reward is ==> 120.04559301696355\n",
            "Episode * 1160 * Steps 283  * Episodic Reward is ==> 274.9222532085796 * Lastest 100 Episods Avg Reward is ==> 129.49894735129757\n",
            "Episode * 1170 * Steps 178  * Episodic Reward is ==> 11.262268598551614 * Lastest 100 Episods Avg Reward is ==> 131.52823423211078\n",
            "Episode * 1180 * Steps 285  * Episodic Reward is ==> 237.45918093529767 * Lastest 100 Episods Avg Reward is ==> 139.20439221720878\n",
            "Episode * 1190 * Steps 256  * Episodic Reward is ==> 34.12893242313794 * Lastest 100 Episods Avg Reward is ==> 147.26439378570606\n",
            "Episode * 1200 * Steps 211  * Episodic Reward is ==> 79.24355204777805 * Lastest 100 Episods Avg Reward is ==> 151.22921837748223\n",
            "Episode * 1210 * Steps 330  * Episodic Reward is ==> 154.28664323933202 * Lastest 100 Episods Avg Reward is ==> 154.01710798115505\n",
            "Episode * 1220 * Steps 583  * Episodic Reward is ==> 253.09854515446446 * Lastest 100 Episods Avg Reward is ==> 158.88884507706334\n",
            "Episode * 1230 * Steps 585  * Episodic Reward is ==> 198.27554939288572 * Lastest 100 Episods Avg Reward is ==> 155.89546272907685\n",
            "Episode * 1240 * Steps 302  * Episodic Reward is ==> 275.46170502979265 * Lastest 100 Episods Avg Reward is ==> 155.37180166193605\n",
            "Episode * 1250 * Steps 892  * Episodic Reward is ==> 216.3887923235613 * Lastest 100 Episods Avg Reward is ==> 156.34058948211378\n",
            "Episode * 1260 * Steps 221  * Episodic Reward is ==> -36.86519226780018 * Lastest 100 Episods Avg Reward is ==> 160.68117434822076\n",
            "Episode * 1270 * Steps 172  * Episodic Reward is ==> 43.415770930682385 * Lastest 100 Episods Avg Reward is ==> 155.71666894683895\n",
            "Episode * 1280 * Steps 304  * Episodic Reward is ==> 169.8624818182078 * Lastest 100 Episods Avg Reward is ==> 147.35339319761928\n",
            "Episode * 1290 * Steps 183  * Episodic Reward is ==> -38.52995745474216 * Lastest 100 Episods Avg Reward is ==> 142.9272261990166\n",
            "Episode * 1300 * Steps 433  * Episodic Reward is ==> 248.58909462549343 * Lastest 100 Episods Avg Reward is ==> 139.15649410711177\n",
            "Episode * 1310 * Steps 672  * Episodic Reward is ==> 146.48044565321277 * Lastest 100 Episods Avg Reward is ==> 141.1286221523798\n",
            "Episode * 1320 * Steps 533  * Episodic Reward is ==> 193.31570072759686 * Lastest 100 Episods Avg Reward is ==> 134.80806512761174\n",
            "Episode * 1330 * Steps 418  * Episodic Reward is ==> -100.47547695221449 * Lastest 100 Episods Avg Reward is ==> 127.50085196365067\n",
            "Episode * 1340 * Steps 570  * Episodic Reward is ==> 201.63212449522976 * Lastest 100 Episods Avg Reward is ==> 124.7571917856847\n",
            "Episode * 1350 * Steps 299  * Episodic Reward is ==> -70.58593222715895 * Lastest 100 Episods Avg Reward is ==> 119.26266530453944\n",
            "Episode * 1360 * Steps 399  * Episodic Reward is ==> 165.26197705627402 * Lastest 100 Episods Avg Reward is ==> 117.8256170500047\n",
            "Episode * 1370 * Steps 836  * Episodic Reward is ==> 106.99361550176846 * Lastest 100 Episods Avg Reward is ==> 112.42279924713556\n",
            "Episode * 1380 * Steps 617  * Episodic Reward is ==> 200.5522574450969 * Lastest 100 Episods Avg Reward is ==> 107.68254579903946\n",
            "Episode * 1390 * Steps 446  * Episodic Reward is ==> 223.08041502277266 * Lastest 100 Episods Avg Reward is ==> 117.35462693683415\n",
            "Episode * 1400 * Steps 239  * Episodic Reward is ==> 6.816660148973767 * Lastest 100 Episods Avg Reward is ==> 127.12657227823539\n",
            "Episode * 1410 * Steps 324  * Episodic Reward is ==> -28.196765877517777 * Lastest 100 Episods Avg Reward is ==> 130.8903297542234\n",
            "Episode * 1420 * Steps 318  * Episodic Reward is ==> 241.49671344597348 * Lastest 100 Episods Avg Reward is ==> 142.64296832669348\n",
            "Episode * 1430 * Steps 248  * Episodic Reward is ==> 242.813927420189 * Lastest 100 Episods Avg Reward is ==> 145.67885545805046\n",
            "Episode * 1440 * Steps 245  * Episodic Reward is ==> 282.7568570887104 * Lastest 100 Episods Avg Reward is ==> 153.2856330477083\n",
            "Episode * 1450 * Steps 262  * Episodic Reward is ==> 237.66098510917027 * Lastest 100 Episods Avg Reward is ==> 160.4020308262722\n",
            "Episode * 1460 * Steps 407  * Episodic Reward is ==> 204.49148618163125 * Lastest 100 Episods Avg Reward is ==> 161.28585311932207\n",
            "Episode * 1470 * Steps 378  * Episodic Reward is ==> 212.09595867002014 * Lastest 100 Episods Avg Reward is ==> 175.84036924847751\n",
            "Episode * 1480 * Steps 646  * Episodic Reward is ==> 187.39084287328762 * Lastest 100 Episods Avg Reward is ==> 186.26307062818546\n",
            "Episode * 1490 * Steps 299  * Episodic Reward is ==> 260.3697535244801 * Lastest 100 Episods Avg Reward is ==> 182.3548340069636\n",
            "Episode * 1500 * Steps 246  * Episodic Reward is ==> 275.8654637579749 * Lastest 100 Episods Avg Reward is ==> 169.86635228996613\n",
            "Episode * 1510 * Steps 310  * Episodic Reward is ==> 222.86090420073984 * Lastest 100 Episods Avg Reward is ==> 174.9260363431502\n",
            "Episode * 1520 * Steps 206  * Episodic Reward is ==> 18.14450266048371 * Lastest 100 Episods Avg Reward is ==> 171.54777318636403\n",
            "Episode * 1530 * Steps 233  * Episodic Reward is ==> -41.09462151479343 * Lastest 100 Episods Avg Reward is ==> 175.12921470168283\n",
            "Episode * 1540 * Steps 384  * Episodic Reward is ==> 263.9081919786914 * Lastest 100 Episods Avg Reward is ==> 174.7641789945136\n",
            "Episode * 1550 * Steps 257  * Episodic Reward is ==> 275.94966709417633 * Lastest 100 Episods Avg Reward is ==> 174.39210478142115\n",
            "Episode * 1560 * Steps 353  * Episodic Reward is ==> 189.74269764659283 * Lastest 100 Episods Avg Reward is ==> 167.00396692025623\n",
            "Episode * 1570 * Steps 210  * Episodic Reward is ==> 8.738857011923074 * Lastest 100 Episods Avg Reward is ==> 158.76010297284026\n",
            "Episode * 1580 * Steps 183  * Episodic Reward is ==> -62.49382399474311 * Lastest 100 Episods Avg Reward is ==> 155.0440634706306\n",
            "Episode * 1590 * Steps 354  * Episodic Reward is ==> 254.52305846133692 * Lastest 100 Episods Avg Reward is ==> 149.85202334615053\n",
            "Episode * 1600 * Steps 248  * Episodic Reward is ==> 254.20299073160763 * Lastest 100 Episods Avg Reward is ==> 154.0096408848058\n",
            "Episode * 1610 * Steps 198  * Episodic Reward is ==> -30.77111516671701 * Lastest 100 Episods Avg Reward is ==> 145.49270138636246\n",
            "Episode * 1620 * Steps 363  * Episodic Reward is ==> 204.63830610695848 * Lastest 100 Episods Avg Reward is ==> 141.96867314228007\n",
            "Episode * 1630 * Steps 248  * Episodic Reward is ==> -6.042012197834623 * Lastest 100 Episods Avg Reward is ==> 135.87722817223164\n",
            "Episode * 1640 * Steps 347  * Episodic Reward is ==> 188.0718927041985 * Lastest 100 Episods Avg Reward is ==> 121.69431713378037\n",
            "Episode * 1650 * Steps 196  * Episodic Reward is ==> -38.33878634627978 * Lastest 100 Episods Avg Reward is ==> 115.50937417928643\n",
            "Episode * 1660 * Steps 421  * Episodic Reward is ==> 153.85574568536356 * Lastest 100 Episods Avg Reward is ==> 120.05637369469824\n",
            "Episode * 1670 * Steps 370  * Episodic Reward is ==> 287.2834316779579 * Lastest 100 Episods Avg Reward is ==> 120.15632640434795\n",
            "Episode * 1680 * Steps 211  * Episodic Reward is ==> -5.618110266989774 * Lastest 100 Episods Avg Reward is ==> 121.54736644979022\n",
            "Episode * 1690 * Steps 151  * Episodic Reward is ==> 3.016914257846139 * Lastest 100 Episods Avg Reward is ==> 126.30419040607337\n",
            "Episode * 1700 * Steps 133  * Episodic Reward is ==> -1.133082831285023 * Lastest 100 Episods Avg Reward is ==> 128.59103446337815\n",
            "Episode * 1710 * Steps 153  * Episodic Reward is ==> 19.997721765396705 * Lastest 100 Episods Avg Reward is ==> 126.19432060033895\n",
            "Episode * 1720 * Steps 252  * Episodic Reward is ==> 246.6086395010128 * Lastest 100 Episods Avg Reward is ==> 132.31214076954083\n",
            "Episode * 1730 * Steps 238  * Episodic Reward is ==> 291.4497027552653 * Lastest 100 Episods Avg Reward is ==> 134.88570229874256\n",
            "Episode * 1740 * Steps 168  * Episodic Reward is ==> 13.650917074968845 * Lastest 100 Episods Avg Reward is ==> 146.27605349202858\n",
            "Episode * 1750 * Steps 194  * Episodic Reward is ==> 295.55736135933745 * Lastest 100 Episods Avg Reward is ==> 157.82281739574162\n",
            "Episode * 1760 * Steps 225  * Episodic Reward is ==> 275.54704521957376 * Lastest 100 Episods Avg Reward is ==> 155.87517332394054\n",
            "Episode * 1770 * Steps 215  * Episodic Reward is ==> 275.08723099042663 * Lastest 100 Episods Avg Reward is ==> 152.12486970469902\n",
            "Episode * 1780 * Steps 384  * Episodic Reward is ==> 293.33818742699077 * Lastest 100 Episods Avg Reward is ==> 152.15149896004954\n",
            "Episode * 1790 * Steps 255  * Episodic Reward is ==> 271.14303321563955 * Lastest 100 Episods Avg Reward is ==> 146.47465524371415\n",
            "Episode * 1800 * Steps 314  * Episodic Reward is ==> 243.19440903342704 * Lastest 100 Episods Avg Reward is ==> 146.24857519095835\n",
            "Episode * 1810 * Steps 282  * Episodic Reward is ==> 253.9658313086962 * Lastest 100 Episods Avg Reward is ==> 156.93908073109844\n",
            "Episode * 1820 * Steps 212  * Episodic Reward is ==> 298.62910134451124 * Lastest 100 Episods Avg Reward is ==> 158.1420043549965\n",
            "Episode * 1830 * Steps 164  * Episodic Reward is ==> -23.93105322556582 * Lastest 100 Episods Avg Reward is ==> 161.73415522144163\n",
            "Episode * 1840 * Steps 233  * Episodic Reward is ==> 211.80248978209627 * Lastest 100 Episods Avg Reward is ==> 161.56930237110564\n",
            "Episode * 1850 * Steps 317  * Episodic Reward is ==> 194.6346994956469 * Lastest 100 Episods Avg Reward is ==> 156.6025004448522\n",
            "Episode * 1860 * Steps 111  * Episodic Reward is ==> -5.991864253591501 * Lastest 100 Episods Avg Reward is ==> 161.93199182840465\n",
            "Episode * 1870 * Steps 313  * Episodic Reward is ==> 288.68667471988397 * Lastest 100 Episods Avg Reward is ==> 164.12013180011968\n",
            "Episode * 1880 * Steps 164  * Episodic Reward is ==> -26.18581062559653 * Lastest 100 Episods Avg Reward is ==> 166.18605636081833\n",
            "Episode * 1890 * Steps 134  * Episodic Reward is ==> -44.06962139251553 * Lastest 100 Episods Avg Reward is ==> 172.69964492240987\n",
            "Episode * 1900 * Steps 286  * Episodic Reward is ==> 256.04214345948344 * Lastest 100 Episods Avg Reward is ==> 177.33645043936463\n",
            "Episode * 1910 * Steps 251  * Episodic Reward is ==> 246.90810997226464 * Lastest 100 Episods Avg Reward is ==> 168.91439613493532\n",
            "Episode * 1920 * Steps 212  * Episodic Reward is ==> 278.6405688004068 * Lastest 100 Episods Avg Reward is ==> 158.704808946773\n",
            "Episode * 1930 * Steps 278  * Episodic Reward is ==> 298.79081840954086 * Lastest 100 Episods Avg Reward is ==> 158.2931550829351\n",
            "Episode * 1940 * Steps 553  * Episodic Reward is ==> 220.27217170050199 * Lastest 100 Episods Avg Reward is ==> 164.43709954917415\n",
            "Episode * 1950 * Steps 137  * Episodic Reward is ==> 15.079029523105461 * Lastest 100 Episods Avg Reward is ==> 155.67029889521103\n",
            "Episode * 1960 * Steps 197  * Episodic Reward is ==> 282.9651781174981 * Lastest 100 Episods Avg Reward is ==> 147.34289001183495\n",
            "Episode * 1970 * Steps 199  * Episodic Reward is ==> 260.90939972821263 * Lastest 100 Episods Avg Reward is ==> 157.18377819692515\n",
            "Episode * 1980 * Steps 128  * Episodic Reward is ==> 40.52217883513683 * Lastest 100 Episods Avg Reward is ==> 158.82894104174187\n",
            "Episode * 1990 * Steps 430  * Episodic Reward is ==> 270.7903878306577 * Lastest 100 Episods Avg Reward is ==> 150.30803524623818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d5c428bc-550e-48c1-a2f2-bdd0ebfa493b\", \"ppo_20210327_214136.csv\", 92388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPw2Dbc7gVW5"
      },
      "source": [
        "def normal_density(x, mu, sigma):\n",
        "    factor= 1./(torch.sqrt(2*np.pi*sigma))\n",
        "    expo = torch.exp(-((x-mu)**2)/(2*sigma))\n",
        "    return factor*expo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEO-kLPoiurL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}